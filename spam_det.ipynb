{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries \n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for word separation operations \n",
    "global len_ham \n",
    "droped = ['\\n','\\t','\\r','\\'','\"',':',';','.','/','!','#','$','%','{','}','(',')','?','&',']','[','-','_']\n",
    "# It is aimed to increase sensitivity and prevent loss of value in float data.\n",
    "comma = 10000000000  \n",
    "len_ham = 0\n",
    "len_spam = 0\n",
    "words_ham = []\n",
    "words_spam = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for Training and Test \n",
    "h_num = 0\n",
    "s_num = 0\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Veri DÃ¼zenleme ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When one of the dropped values appears, replace it with a space .\n",
    "# convert to lowercase \n",
    "# divide words \n",
    "def getWords(data):\n",
    "    for char in droped :\n",
    "        data = data.replace(char,' ')  \n",
    "    data = data.lower() \n",
    "    data = data.split(' ')  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all text files in raw / spam file \n",
    "# count how many they are and do the reading. \ n ",
    "# remove whitespace collect the remainder in word_hs \ n",
    "def getWordsInPath(listpath):\n",
    "    len_hs = 0\n",
    "    word_hs = []    \n",
    "    for f in listdir(listpath+\"/\"): \n",
    "        if f.endswith(\".txt\"): \n",
    "            len_hs += 1 \n",
    "            path = listpath+'/'+str(f)\n",
    "            file = open(path,'r')\n",
    "            text = file.read()            \n",
    "            data = getWords(text)\n",
    "            words = [word for word in data if word != ' '] \n",
    "            word_hs += words \n",
    "            file.close()\n",
    "    return len_hs,word_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global words_ham,words_spam\n",
    "len_ham,words_ham = getWordsInPath(\"training/ham\")\n",
    "len_spam,words_spam = getWordsInPath(\"training/spam\")\n",
    "\n",
    "pHam = float(len_ham)/float(len_ham + len_spam) #P(HAM)\n",
    "pSpam = float(len_spam)/float(len_ham + len_spam) #P(SPAM)\n",
    "\n",
    "# Array each word only once\n",
    "unique_spam = list(set(words_spam)) \n",
    "unique_ham = list(set(words_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham: 375 spam: 375\n",
      "unique_ham: 7818 unique_spam: 10437\n"
     ]
    }
   ],
   "source": [
    "print(\"ham: \" + str(len_ham) + \" spam: \" + str(len_spam))\n",
    "print(\"unique_ham: \" + str(len(unique_ham)) + \" unique_spam: \" + str(len(unique_spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training, Testing ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam ham \n",
    "def getNumberHS(file,spam,ham):\n",
    "    if file.endswith('.spam.txt'):\n",
    "        spam = 1            \n",
    "    elif file.endswith('.ham.txt'):\n",
    "        ham = 1        \n",
    "    else :\n",
    "        print ('WRONG!! : ' + str(file))        \n",
    "    return spam,ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Xi|Y) denominator calculation \n",
    "# Ny + a(smoothing value)n\n",
    "def findDenominator(unique_spam,unique_ham):\n",
    "    a = 1      \n",
    "    N = len(unique_spam) + len(unique_ham) \n",
    "    ham_denom = N + a * len(words_ham) \n",
    "    spam_denom = N + a * len(words_spam)    \n",
    "    return ham_denom,spam_denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding correct and incorrect number of results \n",
    "def compare(h_num,T,F,ishs):\n",
    "    h_num += 1\n",
    "    if ishs :\n",
    "        T += 1\n",
    "    else :\n",
    "        F += 1\n",
    "    return h_num,T,F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(xi) x Q(MNB)\n",
    "def formulate(word,dem_ham,test_read,tempy,uniq_test,words_hs):   \n",
    "    Q = float(words_hs.count(word)+1)/float(dem_ham) # (P(xi,y))\n",
    "    count_word = test_read.count(word)\n",
    "    tempy = tempy*(Q**count_word)\n",
    "    if uniq_test.index(word)%2 == 0: \n",
    "        tempy = tempy * comma   \n",
    "    return tempy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in listdir(\"development/test/\"):\n",
    "    isS = 0\n",
    "    isH = 0\n",
    "    if file.endswith(\".txt\"):\n",
    "        \n",
    "        isspam,isham = getNumberHS(file,isS,isH)        \n",
    "        total += 1\n",
    "        \n",
    "        test = open('development/test/'+str(file),'r')      \n",
    "        test_read = test.read()\n",
    "        \n",
    "        test_read = getWords(test_read)  \n",    
    "        # Array each word only once \ n ",
    "        uniq_test = list(set(test_read)) \n",
    "        \n",
    "        dem_ham,dem_spam = findDenominator(unique_spam,unique_ham)   \n",
    "   \n",
    "        tempy = pHam\n",
    "        for word in uniq_test: \n",
    "            tempy = formulate(word,dem_ham,test_read,tempy,uniq_test,words_ham)\n",
    "            \n",
    "        tem = pSpam\n",
    "        for word in uniq_test:\n",
    "            tem = formulate(word,dem_spam,test_read,tem,uniq_test,words_spam)\n",
    "\n",
    "        if tem < tempy :\n",
    "            h_num,TN,FN = compare(h_num,TN,FN,isham)\n",
    "        \n",
    "        else :\n",
    "            s_num,TP,FP = compare(s_num,TP,FP,isspam)      \n",
    "\n",
    "        test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation ####   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##(spam)selected /            Correct(spam)TP              not correct(not spam)FP\n",
    "\n",
    "##(not spam)not selected /    Correct(spam)FN              not correct(not spam)TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(TP,TN,FN,FP):\n",
    "    P = float(TP)/float(TP+FP)\n",
    "    R = float(TP)/float(TP+FN)\n",
    "    accuracy = str(float(TP+TN)/float(TP+TN+FP+FN))\n",
    "    fmeasure = str(float(2*P*R)/float(P+R))\n",
    "    print('\\n\\nAccuracy(TP+TN)/(TP+TN+FP+FN) : '+accuracy)\n",
    "    print('\\nPrecision(TP/(TP+FP)) : '+ str(P))\n",
    "    print('\\nRecall(TP/(TP+FN)) : '+ str(R))\n",
    "    print('\\nF-Measure(2PR/(P+R)) : '+fmeasure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy(TP+TN)/(TP+TN+FP+FN) : 0.8833333333333333\n",
      "\n",
      "Precision(TP/(TP+FP)) : 0.822429906542056\n",
      "\n",
      "Recall(TP/(TP+FN)) : 0.9777777777777777\n",
      "\n",
      "F-Measure(2PR/(P+R)) : 0.8934010152284264\n"
     ]
    }
   ],
   "source": [
    "evaluation(TP,TN,FN,FP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
